{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca4e90e0",
   "metadata": {},
   "source": [
    "# Going Deeper(CV) - 2. 없다면 어떻게 될까? (ResNet Ablation Study)\n",
    "\n",
    "Deep Residual Learning for Image Recognition에 나오는 ResNet을 구현해 보자.\n",
    "\n",
    "---\n",
    "\n",
    "### 루브릭 평가 기준\n",
    "\n",
    "1. \n",
    "\n",
    "---\n",
    "\n",
    "### 목차\n",
    "\n",
    "0) 필요 모듈 import\n",
    "\n",
    "\n",
    "1) 데이터 로드\n",
    "\n",
    "\n",
    "2) ResNet\n",
    "\n",
    "\n",
    "3) Ablation Study\n",
    "  - ResNet-34 Vs Plain-34\n",
    "  - ResNet-50 Vs Plain-50\n",
    "\n",
    "\n",
    "4) 결과 비교\n",
    "\n",
    "\n",
    "5) 회고\n",
    "\n",
    "\n",
    "## 학습 진행중입니다ㅜㅜ 최대한 빠르게 수정하겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1f908",
   "metadata": {},
   "source": [
    "## 0. 필요 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470b97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce10109",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d99af",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings()\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:]'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1566dd8",
   "metadata": {},
   "source": [
    "train, test의 구분이 없는 데이터이므로 전체 데이터에서 80%를 train set, 20%를 validation set으로 사용한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.data.experimental.cardinality(ds_train))\n",
    "print(tf.data.experimental.cardinality(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0875a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_info.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeec1bf",
   "metadata": {},
   "source": [
    "이미지 크기가 제각각이라 크기가 None으로 표시된다.   \n",
    "이를 학습에 이용하기 위해서는 이미지의 크기를 맞춰주는 과정을 거쳐준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b29a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_info.features[\"label\"].num_classes)\n",
    "\n",
    "print(ds_info.features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20726069",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f79a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_test, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b688038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a5533e",
   "metadata": {},
   "source": [
    "ResNet 만들기  \n",
    "34레이어 모델과 50레이어 모델은 블럭의 구성이 다르므로 이를 구분하여 만들어줄 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77afe985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_block_34(x, channel, kernel_size=3, stride=1, conv_shortcut=True, is_plain=False):\n",
    "    # skip-connection\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(channel, 1, strides=stride, padding='same')(x)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    else:\n",
    "        shortcut = x     \n",
    "    \n",
    "    # CNN layer\n",
    "    if conv_shortcut:\n",
    "        x1 = layers.Conv2D(filters=channel, kernel_size=3, strides=2, padding='same')(x)\n",
    "    else:\n",
    "        x1 = layers.Conv2D(channel, 3, strides=1, padding='same')(x)\n",
    "\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.ReLU()(x1)\n",
    "\n",
    "    x1 = layers.Conv2D(channel, 3, strides=1, padding='same')(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    \n",
    "    if is_plain:\n",
    "        x1 = layers.ReLU()(x1)\n",
    "        return x1\n",
    "    else:\n",
    "        x = layers.Add()([x1, shortcut])\n",
    "        x = layers.ReLU()(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_block_50(x, channel, kernel_size=3, stride=1, conv_shortcut=True, is_plain=False):\n",
    "    # skip-connection\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(channel * 4, 1, strides=stride, padding='same')(x)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    else:\n",
    "        shortcut = x\n",
    "    \n",
    "    # CNN layer\n",
    "    if conv_shortcut:\n",
    "        x1 = layers.Conv2D(channel, 1, strides=stride, padding='same')(x)\n",
    "    else:\n",
    "        x1 = layers.Conv2D(channel, 1, strides=1, padding='same')(x)\n",
    "        \n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.ReLU()(x1)\n",
    "\n",
    "    x1 = layers.Conv2D(channel, 3, strides=1, padding='same')(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    x1 = layers.ReLU()(x1)\n",
    "    \n",
    "    x1 = layers.Conv2D(channel * 4, 1, strides=1, padding='same')(x1)\n",
    "    x1 = layers.BatchNormalization()(x1)\n",
    "    \n",
    "    if is_plain:\n",
    "        x1 = layers.ReLU()(x1)\n",
    "        return x1\n",
    "    else:\n",
    "        x = layers.Add()([x1, shortcut])\n",
    "        x = layers.ReLU()(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a4918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_blocks(input_layer, \n",
    "                        num_cnn=3, \n",
    "                        channel=64, \n",
    "                        strides=1,\n",
    "                        block_num=0, \n",
    "                        is_plain=False, \n",
    "                        is_50=False):\n",
    "    # input layer\n",
    "    x = input_layer\n",
    "    if is_50:\n",
    "        for i in range(num_cnn):\n",
    "            if block_num == 2 and i == 0:\n",
    "                x = build_resnet_block_50(x, channel, is_plain=is_plain)\n",
    "            elif block_num != 2 and i == 0:\n",
    "                x = build_resnet_block_50(x, channel, stride=2, is_plain=is_plain)\n",
    "            else:\n",
    "                x = build_resnet_block_50(x, channel,  conv_shortcut=False, is_plain=is_plain)\n",
    "    else:\n",
    "        for i in range(num_cnn):\n",
    "            if block_num != 2 and i == 0:\n",
    "                x = build_resnet_block_34(x, channel, stride=2, is_plain=is_plain)\n",
    "            else:\n",
    "                x = build_resnet_block_34(x, channel, conv_shortcut=False, is_plain=is_plain)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape=(224, 224, 3), \n",
    "                 num_cnn_list=[3, 4, 6, 3], \n",
    "                 channel_list=[64, 128, 256, 512], \n",
    "                 num_classes=10, \n",
    "                 is_plain=False, \n",
    "                 is_50=False):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) # 모델을 만들기 전에 config list들이 같은 길이인지 확인\n",
    "    \n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    output = input_layer\n",
    "    \n",
    "    # conv1층\n",
    "    output = layers.Conv2D(64, kernel_size=(7, 7), strides=2, padding='same', name='conv1')(output)\n",
    "    output = layers.BatchNormalization()(output)\n",
    "    output = layers.ReLU()(output)\n",
    "    # conv2_x pooling\n",
    "    output = layers.MaxPool2D(pool_size=(3, 3), strides=2, padding='same', name='conv2_maxpool2d')(output)\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output = build_resnet_blocks(output, \n",
    "                                    num_cnn=num_cnn, \n",
    "                                    channel=channel, \n",
    "                                    block_num=i+2,\n",
    "                                    is_plain=is_plain,\n",
    "                                    is_50=is_50)\n",
    "        \n",
    "    output = keras.layers.GlobalAveragePooling2D(name='average_pooling')(output)\n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='softmax', name='predictions')(output)\n",
    "    \n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae246f35",
   "metadata": {},
   "source": [
    "ResNet-34 Vs Plain-34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6938ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCH = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce114fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435dcb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_34 = build_resnet(input_shape=(224, 224, 3))\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb65d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet_34.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet_34 = resnet_34.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba4f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_34 = build_resnet(input_shape=(224, 224, 3), is_plain=True)\n",
    "plain_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57fa7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_34.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_plain_34 = plain_34.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4575dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_resnet_34.history['loss'], 'r')\n",
    "plt.plot(history_plain_34.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet-34'. 'plain-34'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_resnet_34.history['val_accuracy'], 'r')\n",
    "plt.plot(history_plain_34.history['val_accuracy'], 'b')\n",
    "plt.title('Model validation accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet-34'. 'plain-34'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc52861",
   "metadata": {},
   "source": [
    "ResNet-50 Vs Plain-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c597fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50 = build_resnet(input_shape=(224, 224, 3), is_50=True)\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79252ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_50.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_resnet_50 = resnet_50.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abddf578",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_50 = build_resnet(input_shape=(224, 224, 3), is_plain=True, is_50=True)\n",
    "plain_50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9974ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_50.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_plain_50 = plain_50.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train[:80%]'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['train[80%:]'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477169ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6c5bdf9",
   "metadata": {},
   "source": [
    "### 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb37b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564ee57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d7f9f8a",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "#### - 램부족\n",
    "\n",
    "224 크기의 이미지를 사용하다보니 노드 내용과 동일한 크기의 배치 사이즈로 학습을 진행하면 계속해서 램부족으로 인한 세션 종료가 발생했다.  \n",
    "처음에는 원인을 몰라 답답했는데 배치 사이즈를 256에서 32로 줄여주었더니 학습이 정상적으로 진행되었다.  \n",
    "\n",
    "\n",
    "#### - Loss를 알려줘\n",
    "\n",
    "초반의 수많은 시도에서 가장 시간을 많이 쓴 부분은 계속해서 loss 값이 nan으로 뜨는 것이었다.  \n",
    "검색을 통해 학습률을 줄이는 시도를 해보았으나 여전히 nan으로 표시가 되며 학습이 정상적으로 진행되지 않았다.  \n",
    "결국 시간 부족으로 스스로 해결을 하는 것은 포기하고 다른분의 [코드](https://github.com/ceuity/AIFFEL/blob/main/going_deeper_02/resnet_ablation_224.ipynb)를 이용해 학습을 진행하고 추후에 코드를 이해하는 방식으로 방향을 바꾸었다.  GoingDeeper 쉽지 않다ㅜㅜ\n",
    "\n",
    "#### - 무슨 파일이 손상된걸까\n",
    "\n",
    "학습 진행 중\n",
    "> Corrupt JPEG data: 228 extraneous bytes before marker 0xd9 \n",
    "\n",
    "이런 오류가 발생한다.  \n",
    "검색해보니 데이터가 손상되었을 때 나타난다는데 내가 직접 만든 데이터도 아니고 이게 왜 문제가 되는 것일까??  \n",
    "출력창이 매우 길고 지저분해져서 아주 마음에 들지 않는다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
